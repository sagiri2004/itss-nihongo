# ğŸ” PhÃ¢n tÃ­ch: CÃ³ thá»ƒ xÃ³a cÃ¡c Module Local Models khÃ´ng?

## ğŸ“‹ Tá»•ng quan

TÃ i liá»‡u nÃ y phÃ¢n tÃ­ch cÃ¡c module sá»­ dá»¥ng local models (khÃ´ng pháº£i API) vÃ  Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng xÃ³a chÃºng.

---

## ğŸ§  CÃ¡c Module sá»­ dá»¥ng Local Models

### 1. **`pdf_processing/embedding_generator.py`**
- **Local Model**: `sentence-transformers` (SentenceTransformer)
- **Dependencies**: 
  - `torch` (PyTorch)
  - `sentence-transformers`
  - `faiss` (optional, cho fast similarity search)
- **Model**: `paraphrase-multilingual-mpnet-base-v2` hoáº·c `sonoisa/sentence-bert-base-ja-mean-tokens`
- **Chá»©c nÄƒng**: Táº¡o embeddings cho semantic similarity matching

### 2. **`pdf_processing/japanese_nlp.py`**
- **Local Model**: `MeCab` tokenizer
- **Dependencies**: `MeCab`
- **Chá»©c nÄƒng**: Japanese text tokenization, normalization

### 3. **`pdf_processing/text_summarizer.py`**
- **Local Model**: `ginza` / `ja-ginza` (spaCy models)
- **Dependencies**: `ginza`, `ja-ginza`, `spacy`
- **Chá»©c nÄƒng**: Text summarization vá»›i NLP (cÃ³ option dÃ¹ng LLM API)
- **LÆ°u Ã½**: CÃ³ `use_llm=True` option Ä‘á»ƒ dÃ¹ng Gemini API thay vÃ¬ local NLP

### 4. **`matching/semantic_matcher.py`**
- **Dependencies**: Sá»­ dá»¥ng `EmbeddingGenerator` (giÃ¡n tiáº¿p dÃ¹ng sentence-transformers)
- **Chá»©c nÄƒng**: Semantic matching dá»±a trÃªn embeddings

### 5. **`matching/exact_matcher.py`** vÃ  **`matching/fuzzy_matcher.py`**
- **Local Processing**: KhÃ´ng dÃ¹ng ML models, chá»‰ text matching
- **CÃ³ thá»ƒ xÃ³a**: âŒ KhÃ´ng, vÃ¬ khÃ´ng pháº£i local models, chá»‰ lÃ  text processing

---

## ğŸ”— Dependency Chain

```
SlideProcessor
  â”œâ”€â”€ EmbeddingGenerator (sentence-transformers) â† LOCAL MODEL
  â”œâ”€â”€ JapaneseNLP (MeCab) â† LOCAL MODEL
  â”œâ”€â”€ KeywordIndexer (text processing only)
  â”œâ”€â”€ TextSummarizer (ginza/spaCy) â† LOCAL MODEL (cÃ³ option use_llm)
  â”œâ”€â”€ ExactMatcher (text matching only)
  â”œâ”€â”€ FuzzyMatcher (text matching only)
  â””â”€â”€ SemanticMatcher (dÃ¹ng EmbeddingGenerator) â† LOCAL MODEL
```

---

## ğŸ“Š Sá»­ dá»¥ng trong Routers

### 1. **`/slides` Router (slides.py)**

#### Hiá»‡n táº¡i:
- âœ… **Chá»‰ dÃ¹ng `GeminiProcessor()`** - API-based, khÃ´ng dÃ¹ng local models
- âœ… `TextSummarizer` Ä‘Æ°á»£c dÃ¹ng trong `_generate_all_summary()` nhÆ°ng vá»›i **`use_llm=True`** (dÃ¹ng Gemini API)
- âŒ `SlideProcessor` **KHÃ”NG Ä‘Æ°á»£c sá»­ dá»¥ng** trong code hiá»‡n táº¡i
- âš ï¸ `use_embeddings` parameter cÃ³ nhÆ°ng **khÃ´ng Ä‘Æ°á»£c dÃ¹ng** (comment: "Not used with Gemini")

#### Code hiá»‡n táº¡i:
```python
# Chá»‰ dÃ¹ng GeminiProcessor (API)
processor = GeminiProcessor()
result = processor.process_pdf(str(temp_path))

# TextSummarizer vá»›i use_llm=True (API)
summarizer = TextSummarizer(use_llm=use_llm)  # use_llm=True máº·c Ä‘á»‹nh
```

### 2. **`/ws` Router (transcription.py)**

#### Qua `result_handler`:
- âš ï¸ `result_handler.preload_slides()` cÃ³ thá»ƒ dÃ¹ng `SlideProcessor`
- âš ï¸ NhÆ°ng **`use_embeddings=False` máº·c Ä‘á»‹nh**
- âš ï¸ Chá»‰ dÃ¹ng náº¿u `enable_slide_matching=True`

#### Code:
```python
# result_handler.py
def preload_slides(
    self,
    pdf_path: str,
    storage_service = None,
    use_embeddings: bool = False  # â† Máº¶C Äá»ŠNH FALSE
) -> Dict:
    if use_embeddings:
        # Chá»‰ load embeddings náº¿u explicitly set True
        self.slide_processor = SlideProcessor(..., use_embeddings=True)
```

---

## âœ… Káº¿t luáº­n: CÃ³ thá»ƒ xÃ³a khÃ´ng?

### ğŸŸ¢ **CÃ“ THá»‚ XÃ“A** cÃ¡c module sau:

#### 1. **`pdf_processing/embedding_generator.py`** âœ…
- **LÃ½ do**: 
  - KhÃ´ng Ä‘Æ°á»£c dÃ¹ng trong `/slides` router (dÃ¹ng GeminiProcessor)
  - KhÃ´ng Ä‘Æ°á»£c dÃ¹ng trong `/ws` router (use_embeddings=False máº·c Ä‘á»‹nh)
  - Chá»‰ Ä‘Æ°á»£c dÃ¹ng khi `SlideProcessor` vá»›i `use_embeddings=True`
  - âš ï¸ CÃ³ trong `google_cloud/speech_to_text.py` nhÆ°ng module nÃ y khÃ´ng Ä‘Æ°á»£c dÃ¹ng trong routers
- **Rá»§i ro**: Tháº¥p - khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong production code hiá»‡n táº¡i (routers)

#### 2. **`matching/semantic_matcher.py`** âœ…
- **LÃ½ do**: 
  - Phá»¥ thuá»™c vÃ o `EmbeddingGenerator`
  - Chá»‰ Ä‘Æ°á»£c dÃ¹ng khi `SlideProcessor` vá»›i `use_embeddings=True`
- **Rá»§i ro**: Tháº¥p - khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong production code hiá»‡n táº¡i

#### 3. **`pdf_processing/japanese_nlp.py`** âš ï¸
- **LÃ½ do**: 
  - ÄÆ°á»£c dÃ¹ng bá»Ÿi `SlideProcessor` (nhÆ°ng SlideProcessor khÃ´ng Ä‘Æ°á»£c dÃ¹ng)
  - CÃ³ thá»ƒ Ä‘Æ°á»£c dÃ¹ng bá»Ÿi cÃ¡c module khÃ¡c
- **Rá»§i ro**: Trung bÃ¬nh - cáº§n kiá»ƒm tra xem cÃ³ module nÃ o khÃ¡c dÃ¹ng khÃ´ng

### ğŸŸ¡ **Cáº¦N Cáº¨N THáº¬N**:

#### 4. **`pdf_processing/text_summarizer.py`** âš ï¸
- **LÃ½ do**: 
  - âœ… ÄÆ°á»£c dÃ¹ng trong `/slides` router
  - âœ… NhÆ°ng vá»›i `use_llm=True` (dÃ¹ng Gemini API)
  - âš ï¸ CÃ³ fallback vá» local NLP náº¿u `use_llm=False`
- **Rá»§i ro**: Trung bÃ¬nh - cÃ³ thá»ƒ cáº§n fallback
- **Khuyáº¿n nghá»‹**: Giá»¯ láº¡i nhÆ°ng cÃ³ thá»ƒ tá»‘i Æ°u Ä‘á»ƒ chá»‰ dÃ¹ng LLM mode

### ğŸ”´ **KHÃ”NG NÃŠN XÃ“A**:

#### 5. **`matching/exact_matcher.py`** vÃ  **`matching/fuzzy_matcher.py`** âŒ
- **LÃ½ do**: 
  - KhÃ´ng pháº£i local models, chá»‰ lÃ  text processing
  - CÃ³ thá»ƒ Ä‘Æ°á»£c dÃ¹ng trong `SlideProcessor` (náº¿u Ä‘Æ°á»£c enable)
- **Rá»§i ro**: Tháº¥p náº¿u xÃ³a, nhÆ°ng khÃ´ng cáº§n thiáº¿t vÃ¬ khÃ´ng pháº£i local models

---

## ğŸ¯ Khuyáº¿n nghá»‹

### âœ… **AN TOÃ€N Äá»‚ XÃ“A**:

1. **`pdf_processing/embedding_generator.py`**
   - KhÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong production
   - Tiáº¿t kiá»‡m: `torch`, `sentence-transformers`, `faiss` dependencies

2. **`matching/semantic_matcher.py`**
   - Phá»¥ thuá»™c vÃ o `EmbeddingGenerator`
   - KhÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong production

### âš ï¸ **Cáº¦N KIá»‚M TRA TRÆ¯á»šC KHI XÃ“A**:

3. **`pdf_processing/japanese_nlp.py`**
   - Kiá»ƒm tra xem cÃ³ module nÃ o khÃ¡c dÃ¹ng `JapaneseNLP` khÃ´ng
   - Náº¿u khÃ´ng, cÃ³ thá»ƒ xÃ³a

### ğŸ”„ **Tá»I Æ¯U THAY VÃŒ XÃ“A**:

4. **`pdf_processing/text_summarizer.py`**
   - Giá»¯ láº¡i nhÆ°ng tá»‘i Æ°u Ä‘á»ƒ chá»‰ support LLM mode
   - XÃ³a code liÃªn quan Ä‘áº¿n ginza/spaCy náº¿u khÃ´ng cáº§n fallback

---

## ğŸ“¦ Dependencies cÃ³ thá»ƒ xÃ³a náº¿u xÃ³a cÃ¡c module trÃªn:

### Náº¿u xÃ³a `embedding_generator.py` vÃ  `semantic_matcher.py`:
- `torch` (PyTorch) - ~2GB
- `sentence-transformers` - ~500MB
- `faiss` hoáº·c `faiss-cpu` - ~100MB
- **Tá»•ng tiáº¿t kiá»‡m**: ~2.6GB

### Náº¿u xÃ³a `japanese_nlp.py`:
- `mecab-python3` - ~10MB
- **Tá»•ng tiáº¿t kiá»‡m**: ~10MB

### Náº¿u tá»‘i Æ°u `text_summarizer.py` (chá»‰ LLM mode):
- `ginza` - ~200MB
- `ja-ginza` - ~500MB
- `spacy` - ~100MB
- **Tá»•ng tiáº¿t kiá»‡m**: ~800MB

### **Tá»•ng tiáº¿t kiá»‡m tiá»m nÄƒng**: ~3.4GB

---

## ğŸ§ª CÃ¡ch kiá»ƒm tra trÆ°á»›c khi xÃ³a:

1. **Kiá»ƒm tra imports:**
   ```bash
   grep -r "from.*embedding_generator\|import.*EmbeddingGenerator" src/
   grep -r "from.*japanese_nlp\|import.*JapaneseNLP" src/
   grep -r "from.*semantic_matcher\|import.*SemanticMatcher" src/
   ```

2. **Kiá»ƒm tra tests:**
   ```bash
   grep -r "EmbeddingGenerator\|JapaneseNLP\|SemanticMatcher" tests/
   ```

3. **Kiá»ƒm tra usage trong code:**
   ```bash
   grep -r "use_embeddings.*True\|use_embeddings=True" src/
   ```

---

## âœ… Káº¿t luáº­n cuá»‘i cÃ¹ng

### **CÃ“ THá»‚ XÃ“A AN TOÃ€N:**
- âœ… `pdf_processing/embedding_generator.py`
- âœ… `matching/semantic_matcher.py`

### **Cáº¦N KIá»‚M TRA:**
- âš ï¸ `pdf_processing/japanese_nlp.py`

### **Tá»I Æ¯U THAY VÃŒ XÃ“A:**
- ğŸ”„ `pdf_processing/text_summarizer.py` - Giá»¯ láº¡i nhÆ°ng chá»‰ support LLM mode

### **KHÃ”NG XÃ“A:**
- âŒ `matching/exact_matcher.py`
- âŒ `matching/fuzzy_matcher.py`

