<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Speech-to-Text Demo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      :root {
        color-scheme: light dark;
        font-family: "Segoe UI", Roboto, sans-serif;
        background: #0d1117;
        color: #e6edf3;
      }

      body {
        margin: 0;
        min-height: 100vh;
        display: flex;
        flex-direction: column;
      }

      header {
        padding: 24px;
        text-align: center;
        background: linear-gradient(135deg, #2563eb, #7c3aed);
        color: #fff;
      }

      main {
        flex: 1;
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
        gap: 24px;
        padding: 24px;
      }

      section {
        border: 1px solid #30363d;
        border-radius: 12px;
        padding: 20px;
        background: rgba(13, 17, 23, 0.85);
        backdrop-filter: blur(10px);
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.25);
      }

      h2 {
        margin-top: 0;
      }

      label {
        display: block;
        margin-bottom: 8px;
        font-weight: 600;
      }

      input[type="file"],
      select {
        width: 100%;
        padding: 10px;
        border: 1px solid #30363d;
        border-radius: 8px;
        background: #161b22;
        color: inherit;
        margin-bottom: 16px;
      }

      button {
        display: inline-flex;
        align-items: center;
        gap: 8px;
        cursor: pointer;
        padding: 10px 18px;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        transition: transform 0.15s ease, box-shadow 0.15s ease;
      }

      button.primary {
        background: linear-gradient(135deg, #2563eb, #7c3aed);
        color: #fff;
        box-shadow: 0 8px 20px rgba(37, 99, 235, 0.35);
      }

      button.danger {
        background: #ef4444;
        color: #fff;
      }

      button:disabled {
        opacity: 0.65;
        cursor: not-allowed;
        box-shadow: none;
      }

      button:not(:disabled):hover {
        transform: translateY(-1px);
        box-shadow: 0 12px 28px rgba(37, 99, 235, 0.35);
      }

      pre {
        background: #0b0f15;
        border-radius: 8px;
        padding: 16px;
        max-height: 280px;
        overflow: auto;
        border: 1px solid #1f2937;
      }

      #transcriptLog {
        display: flex;
        flex-direction: column;
        gap: 12px;
        max-height: 320px;
        overflow: auto;
      }

      .transcript-item {
        background: rgba(37, 99, 235, 0.08);
        border: 1px solid rgba(37, 99, 235, 0.25);
        border-radius: 10px;
        padding: 12px;
        line-height: 1.5;
      }

      .transcript-item.final {
        background: rgba(34, 197, 94, 0.12);
        border-color: rgba(34, 197, 94, 0.3);
      }

      .status {
        font-size: 0.9rem;
        opacity: 0.8;
      }

      footer {
        padding: 12px 24px;
        text-align: center;
        font-size: 0.85rem;
        color: #9ca3af;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Speech-to-Text Demo</h1>
      <p>Upload slide PDFs v√† tr·∫£i nghi·ªám ghi √¢m tr·ª±c ti·∫øp qua FastAPI</p>
    </header>

    <main>
      <section>
        <h2>1. Upload Slides</h2>
        <form id="slideForm">
          <label for="pdfInput">PDF Slide</label>
          <input id="pdfInput" type="file" accept="application/pdf" required />

          <label for="embeddingToggle">S·ª≠ d·ª•ng Embeddings</label>
          <select id="embeddingToggle">
            <option value="true" selected>True</option>
            <option value="false">False</option>
          </select>

          <button id="uploadBtn" class="primary" type="submit">Upload &amp; Process</button>
        </form>

        <h3>K·∫øt qu·∫£</h3>
        <pre id="slideResult">{}</pre>
      </section>

      <section>
        <h2>2. Speech-to-Text</h2>
        <div>
          <label for="languageSelect">Language</label>
          <select id="languageSelect">
            <option value="ja-JP">Japanese (ja-JP)</option>
            <option value="en-US">English (en-US)</option>
            <option value="vi-VN">Vietnamese (vi-VN)</option>
          </select>
        </div>
        <div>
          <label for="modelSelect">Model</label>
          <select id="modelSelect">
            <option value="latest_long">latest_long</option>
            <option value="latest_short">latest_short</option>
            <option value="chirp">chirp</option>
          </select>
        </div>
        <div style="margin-bottom: 16px;">
          <button id="startBtn" class="primary">üî¥ Start Recording</button>
          <button id="stopBtn" class="danger" disabled>‚èπÔ∏è Stop</button>
        </div>
        <div class="status" id="recordingStatus">Status: idle</div>

        <h3>K·∫øt qu·∫£ theo th·ªùi gian th·ª±c</h3>
        <div id="transcriptLog"></div>
      </section>
    </main>

    <footer>FastAPI ‚Ä¢ Google Cloud Speech-to-Text V2 ‚Ä¢ WebRTC Microphone Demo</footer>

    <script>
      const slideForm = document.querySelector("#slideForm");
      const pdfInput = document.querySelector("#pdfInput");
      const embeddingToggle = document.querySelector("#embeddingToggle");
      const slideResult = document.querySelector("#slideResult");
      const uploadBtn = document.querySelector("#uploadBtn");

      slideForm.addEventListener("submit", async (event) => {
        event.preventDefault();
        if (!pdfInput.files.length) return;

        uploadBtn.disabled = true;
        uploadBtn.textContent = "Processing...";

        const formData = new FormData();
        formData.append("file", pdfInput.files[0]);
        formData.append("use_embeddings", embeddingToggle.value);

        try {
          const response = await fetch("/slides/upload", {
            method: "POST",
            body: formData,
          });
          if (!response.ok) {
            throw new Error(await response.text());
          }
          const data = await response.json();
          slideResult.textContent = JSON.stringify(data, null, 2);
        } catch (err) {
          slideResult.textContent = `Error: ${err}`;
        } finally {
          uploadBtn.disabled = false;
          uploadBtn.textContent = "Upload & Process";
        }
      });

      const startBtn = document.querySelector("#startBtn");
      const stopBtn = document.querySelector("#stopBtn");
      const recordingStatus = document.querySelector("#recordingStatus");
      const transcriptLog = document.querySelector("#transcriptLog");
      const languageSelect = document.querySelector("#languageSelect");
      const modelSelect = document.querySelector("#modelSelect");

      let websocket = null;
      let mediaStream = null;
      let audioContext = null;
      let processor = null;
      let sessionId = null;
      let pendingSamples = new Float32Array(0);
      const TARGET_CHUNK_SAMPLES = 1600; // 100ms at 16kHz mono

      function appendTranscript({ text, is_final, confidence }) {
        const item = document.createElement("div");
        item.className = `transcript-item ${is_final ? "final" : ""}`;
        item.innerHTML = `
          <div>${text}</div>
          <div style="font-size: 0.8rem; opacity: 0.8;">Final: ${is_final ? "Yes" : "No"} ‚Ä¢ Confidence: ${(confidence * 100).toFixed(1)}%</div>
        `;
        transcriptLog.prepend(item);
      }

      function downsampleBuffer(buffer, inputSampleRate, targetSampleRate) {
        if (targetSampleRate === inputSampleRate) {
          return buffer;
        }
        const sampleRateRatio = inputSampleRate / targetSampleRate;
        const newLength = Math.round(buffer.length / sampleRateRatio);
        const result = new Float32Array(newLength);
        let offsetResult = 0;
        let offsetBuffer = 0;
        while (offsetResult < result.length) {
          const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
          let accum = 0;
          let count = 0;
          for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i += 1) {
            accum += buffer[i];
            count += 1;
          }
          result[offsetResult] = accum / count;
          offsetResult += 1;
          offsetBuffer = nextOffsetBuffer;
        }
        return result;
      }

      function floatTo16BitPCM(floatBuffer) {
        const output = new Int16Array(floatBuffer.length);
        for (let i = 0; i < floatBuffer.length; i += 1) {
          const s = Math.max(-1, Math.min(1, floatBuffer[i]));
          output[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
        }
        return output.buffer;
      }

      async function startRecording() {
        transcriptLog.innerHTML = "";
        try {
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
        } catch (err) {
          recordingStatus.textContent = `Status: microphone access denied (${err})`;
          return;
        }
        pendingSamples = new Float32Array(0);

        websocket = new WebSocket(`${location.protocol === "https:" ? "wss" : "ws"}://${location.host}/ws/transcribe`);

        websocket.addEventListener("open", () => {
          recordingStatus.textContent = "Status: connected";
          sessionId = crypto.randomUUID();
          websocket.send(JSON.stringify({
            action: "start",
            session_id: sessionId,
            presentation_id: sessionId,
            language_code: languageSelect.value,
            model: modelSelect.value,
            enable_interim_results: true,
          }));
        });

        websocket.addEventListener("message", (event) => {
          try {
            const data = JSON.parse(event.data);
            if (data.event === "transcription") {
              appendTranscript(data.result);
            } else if (data.event === "session_started") {
              recordingStatus.textContent = "Status: recording...";
            } else if (data.event === "session_closed") {
              recordingStatus.textContent = "Status: session closed";
              startBtn.disabled = false;
              stopBtn.disabled = true;
            } else if (data.event === "error") {
              recordingStatus.textContent = `Status: error - ${data.message}`;
              startBtn.disabled = false;
              stopBtn.disabled = true;
            }
          } catch (err) {
            console.warn("Invalid message", event.data);
          }
        });

        websocket.addEventListener("close", () => {
          recordingStatus.textContent = "Status: disconnected";
          startBtn.disabled = false;
          stopBtn.disabled = true;
        });

        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        if (audioContext.state === "suspended") {
          await audioContext.resume();
        }
        const source = audioContext.createMediaStreamSource(mediaStream);

        processor = audioContext.createScriptProcessor(2048, 1, 1);
        processor.onaudioprocess = (event) => {
          if (!websocket || websocket.readyState !== WebSocket.OPEN) {
            return;
          }
          const inputBuffer = event.inputBuffer.getChannelData(0);
          const downsampled = downsampleBuffer(inputBuffer, audioContext.sampleRate, 16000);
          if (downsampled.length === 0) {
            return;
          }

          const combined = new Float32Array(pendingSamples.length + downsampled.length);
          combined.set(pendingSamples);
          combined.set(downsampled, pendingSamples.length);
          pendingSamples = combined;

          while (pendingSamples.length >= TARGET_CHUNK_SAMPLES) {
            const chunkSamples = pendingSamples.slice(0, TARGET_CHUNK_SAMPLES);
            pendingSamples = pendingSamples.slice(TARGET_CHUNK_SAMPLES);
            if (websocket && websocket.readyState === WebSocket.OPEN) {
              const pcm = floatTo16BitPCM(chunkSamples);
              websocket.send(pcm);
            }
          }
        };

        source.connect(processor);
        processor.connect(audioContext.destination);

        startBtn.disabled = true;
        stopBtn.disabled = false;
        recordingStatus.textContent = "Status: connecting...";
      }

      async function stopRecording() {
        stopBtn.disabled = true;

        if (processor) {
          processor.disconnect();
          processor = null;
        }
        if (audioContext) {
          await audioContext.close();
          audioContext = null;
        }
        if (mediaStream) {
          mediaStream.getTracks().forEach((track) => track.stop());
          mediaStream = null;
        }
        pendingSamples = new Float32Array(0);

        if (websocket && websocket.readyState === WebSocket.OPEN) {
          websocket.send(JSON.stringify({ action: "stop" }));
        }
        setTimeout(() => {
          if (websocket) {
            websocket.close();
            websocket = null;
          }
        }, 250);

        recordingStatus.textContent = "Status: idle";
        startBtn.disabled = false;
        stopBtn.disabled = true;
        sessionId = null;
      }

      startBtn.addEventListener("click", () => {
        startRecording();
      });

      stopBtn.addEventListener("click", () => {
        stopRecording();
      });

      window.addEventListener("beforeunload", () => {
        if (websocket && websocket.readyState === WebSocket.OPEN) {
          websocket.close();
        }
      });
    </script>
  </body>
</html>

