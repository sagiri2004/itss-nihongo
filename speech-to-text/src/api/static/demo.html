<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Speech-to-Text Demo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      :root {
        color-scheme: light dark;
        font-family: "Segoe UI", Roboto, sans-serif;
        background: #0d1117;
        color: #e6edf3;
      }

      body {
        margin: 0;
        min-height: 100vh;
        display: flex;
        flex-direction: column;
      }

      header {
        padding: 24px;
        text-align: center;
        background: linear-gradient(135deg, #2563eb, #7c3aed);
        color: #fff;
      }

      main {
        flex: 1;
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
        gap: 24px;
        padding: 24px;
      }

      section {
        border: 1px solid #30363d;
        border-radius: 12px;
        padding: 20px;
        background: rgba(13, 17, 23, 0.85);
        backdrop-filter: blur(10px);
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.25);
      }

      h2 {
        margin-top: 0;
      }

      label {
        display: block;
        margin-bottom: 8px;
        font-weight: 600;
      }

      input[type="file"],
      select {
        width: 100%;
        padding: 10px;
        border: 1px solid #30363d;
        border-radius: 8px;
        background: #161b22;
        color: inherit;
        margin-bottom: 16px;
      }

      button {
        display: inline-flex;
        align-items: center;
        gap: 8px;
        cursor: pointer;
        padding: 10px 18px;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        transition: transform 0.15s ease, box-shadow 0.15s ease;
      }

      button.primary {
        background: linear-gradient(135deg, #2563eb, #7c3aed);
        color: #fff;
        box-shadow: 0 8px 20px rgba(37, 99, 235, 0.35);
      }

      button.danger {
        background: #ef4444;
        color: #fff;
      }

      button:disabled {
        opacity: 0.65;
        cursor: not-allowed;
        box-shadow: none;
      }

      button:not(:disabled):hover {
        transform: translateY(-1px);
        box-shadow: 0 12px 28px rgba(37, 99, 235, 0.35);
      }

      pre {
        background: #0b0f15;
        border-radius: 8px;
        padding: 16px;
        max-height: 280px;
        overflow: auto;
        border: 1px solid #1f2937;
      }

      #transcriptLog {
        display: flex;
        flex-direction: column;
        gap: 12px;
        max-height: 320px;
        overflow: auto;
      }

      .transcript-item {
        background: rgba(37, 99, 235, 0.08);
        border: 1px solid rgba(37, 99, 235, 0.25);
        border-radius: 10px;
        padding: 12px;
        line-height: 1.5;
      }

      .transcript-item.final {
        background: rgba(34, 197, 94, 0.12);
        border-color: rgba(34, 197, 94, 0.3);
      }

      .status {
        font-size: 0.9rem;
        opacity: 0.8;
      }

      footer {
        padding: 12px 24px;
        text-align: center;
        font-size: 0.85rem;
        color: #9ca3af;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Speech-to-Text Demo</h1>
      <p>Upload slide PDFs v√† tr·∫£i nghi·ªám ghi √¢m tr·ª±c ti·∫øp qua FastAPI</p>
    </header>

    <main>
      <section>
        <h2>1. Upload Slides</h2>
        <form id="slideForm">
          <label for="pdfInput">PDF Slide</label>
          <input id="pdfInput" type="file" accept="application/pdf" required />

          <label for="embeddingToggle">S·ª≠ d·ª•ng Embeddings</label>
          <select id="embeddingToggle">
            <option value="true" selected>True</option>
            <option value="false">False</option>
          </select>

          <button id="uploadBtn" class="primary" type="submit">Upload &amp; Process</button>
        </form>

        <h3>K·∫øt qu·∫£</h3>
        <pre id="slideResult">{}</pre>
      </section>

      <section>
        <h2>2. Speech-to-Text</h2>
        <div>
          <label for="lectureIdInput">Lecture ID (required)</label>
          <input id="lectureIdInput" type="text" placeholder="Enter lecture ID or leave empty for auto-generate" style="width: 100%; padding: 10px; border: 1px solid #30363d; border-radius: 8px; background: #161b22; color: inherit; margin-bottom: 16px;" />
        </div>
        <div>
          <label for="languageSelect">Language</label>
          <select id="languageSelect">
            <option value="ja-JP">Japanese (ja-JP)</option>
            <option value="en-US">English (en-US)</option>
            <option value="vi-VN">Vietnamese (vi-VN)</option>
          </select>
        </div>
        <div>
          <label for="modelSelect">Model</label>
          <select id="modelSelect">
            <option value="latest_long">latest_long</option>
            <option value="latest_short">latest_short</option>
            <option value="chirp">chirp</option>
          </select>
        </div>
        <div style="margin-bottom: 16px;">
          <button id="startBtn" class="primary">üî¥ Start Recording</button>
          <button id="stopBtn" class="danger" disabled>‚èπÔ∏è Stop</button>
        </div>
        <div class="status" id="recordingStatus">Status: idle</div>

        <h3>K·∫øt qu·∫£ theo th·ªùi gian th·ª±c</h3>
        <div id="transcriptLog"></div>
      </section>
    </main>

    <footer>FastAPI ‚Ä¢ Google Cloud Speech-to-Text V2 ‚Ä¢ WebRTC Microphone Demo</footer>

    <script>
      const slideForm = document.querySelector("#slideForm");
      const pdfInput = document.querySelector("#pdfInput");
      const embeddingToggle = document.querySelector("#embeddingToggle");
      const slideResult = document.querySelector("#slideResult");
      const uploadBtn = document.querySelector("#uploadBtn");

      slideForm.addEventListener("submit", async (event) => {
        event.preventDefault();
        if (!pdfInput.files.length) return;

        uploadBtn.disabled = true;
        uploadBtn.textContent = "Processing...";

        const formData = new FormData();
        formData.append("file", pdfInput.files[0]);
        formData.append("use_embeddings", embeddingToggle.value);

        try {
          const response = await fetch("/slides/upload", {
            method: "POST",
            body: formData,
          });
          if (!response.ok) {
            throw new Error(await response.text());
          }
          const data = await response.json();
          slideResult.textContent = JSON.stringify(data, null, 2);
        } catch (err) {
          slideResult.textContent = `Error: ${err}`;
        } finally {
          uploadBtn.disabled = false;
          uploadBtn.textContent = "Upload & Process";
        }
      });

      const startBtn = document.querySelector("#startBtn");
      const stopBtn = document.querySelector("#stopBtn");
      const recordingStatus = document.querySelector("#recordingStatus");
      const transcriptLog = document.querySelector("#transcriptLog");
      const languageSelect = document.querySelector("#languageSelect");
      const modelSelect = document.querySelector("#modelSelect");
      const lectureIdInput = document.querySelector("#lectureIdInput");

      let websocket = null;
      let mediaStream = null;
      let audioContext = null;
      let processor = null;
      let sessionId = null;
      let pendingSamples = new Float32Array(0);
      const TARGET_CHUNK_SAMPLES = 1600; // 100ms at 16kHz mono

      function appendTranscript({ text, is_final, confidence }) {
        const item = document.createElement("div");
        item.className = `transcript-item ${is_final ? "final" : ""}`;
        item.innerHTML = `
          <div>${text}</div>
          <div style="font-size: 0.8rem; opacity: 0.8;">Final: ${is_final ? "Yes" : "No"} ‚Ä¢ Confidence: ${(confidence * 100).toFixed(1)}%</div>
        `;
        transcriptLog.prepend(item);
      }

      function downsampleBuffer(buffer, inputSampleRate, targetSampleRate) {
        if (targetSampleRate === inputSampleRate) {
          return buffer;
        }
        const sampleRateRatio = inputSampleRate / targetSampleRate;
        const newLength = Math.round(buffer.length / sampleRateRatio);
        const result = new Float32Array(newLength);
        let offsetResult = 0;
        let offsetBuffer = 0;
        while (offsetResult < result.length) {
          const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
          let accum = 0;
          let count = 0;
          for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i += 1) {
            accum += buffer[i];
            count += 1;
          }
          result[offsetResult] = accum / count;
          offsetResult += 1;
          offsetBuffer = nextOffsetBuffer;
        }
        return result;
      }

      function floatTo16BitPCM(floatBuffer) {
        const output = new Int16Array(floatBuffer.length);
        for (let i = 0; i < floatBuffer.length; i += 1) {
          const s = Math.max(-1, Math.min(1, floatBuffer[i]));
          output[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
        }
        return output.buffer;
      }

      // Polyfill for getUserMedia for older browsers
      function getUserMedia(constraints) {
        // #region agent log
        const DEBUG_LOG_URL = 'http://127.0.0.1:7242/ingest/2b24f1d2-cbbe-41fa-9147-751f82eade36';
        try {
          fetch(DEBUG_LOG_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              location: 'demo.html:getUserMedia',
              message: 'Checking getUserMedia support',
              data: {
                hasMediaDevices: !!navigator.mediaDevices,
                hasGetUserMedia: !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia),
                userAgent: navigator.userAgent
              },
              timestamp: Date.now(),
              sessionId: 'debug-session',
              runId: 'run1',
              hypothesisId: 'A'
            })
          }).catch(() => {});
        } catch (e) {}
        // #endregion

        // Modern API (Chrome, Firefox, Safari 11+)
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          return navigator.mediaDevices.getUserMedia(constraints);
        }

        // Legacy API with promise wrapper
        const getUserMedia = navigator.getUserMedia ||
                            navigator.webkitGetUserMedia ||
                            navigator.mozGetUserMedia ||
                            navigator.msGetUserMedia;

        if (!getUserMedia) {
          // #region agent log
          try {
            fetch(DEBUG_LOG_URL, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                location: 'demo.html:getUserMedia',
                message: 'getUserMedia not supported',
                data: { error: 'getUserMedia is not supported in this browser' },
                timestamp: Date.now(),
                sessionId: 'debug-session',
                runId: 'run1',
                hypothesisId: 'B'
              })
            }).catch(() => {});
          } catch (e) {}
          // #endregion
          return Promise.reject(new Error('getUserMedia is not supported in this browser'));
        }

        return new Promise((resolve, reject) => {
          getUserMedia.call(navigator, constraints, resolve, reject);
        });
      }

      async function startRecording() {
        transcriptLog.innerHTML = "";
        
        // #region agent log
        const DEBUG_LOG_URL = 'http://127.0.0.1:7242/ingest/2b24f1d2-cbbe-41fa-9147-751f82eade36';
        try {
          fetch(DEBUG_LOG_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              location: 'demo.html:startRecording',
              message: 'Starting recording',
              data: {
                protocol: location.protocol,
                host: location.host,
                isSecure: location.protocol === 'https:' || location.hostname === 'localhost' || location.hostname === '127.0.0.1'
              },
              timestamp: Date.now(),
              sessionId: 'debug-session',
              runId: 'run1',
              hypothesisId: 'C'
            })
          }).catch(() => {});
        } catch (e) {}
        // #endregion

        try {
          // Check if we're on a secure context (HTTPS or localhost)
          if (location.protocol !== 'https:' && 
              location.hostname !== 'localhost' && 
              location.hostname !== '127.0.0.1' && 
              location.hostname !== '0.0.0.0') {
            const errorMsg = 'Microphone access requires HTTPS or localhost. Current: ' + location.protocol + '//' + location.host;
            recordingStatus.textContent = `Status: ${errorMsg}`;
            // #region agent log
            try {
              fetch(DEBUG_LOG_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  location: 'demo.html:startRecording',
                  message: 'Insecure context error',
                  data: { error: errorMsg },
                  timestamp: Date.now(),
                  sessionId: 'debug-session',
                  runId: 'run1',
                  hypothesisId: 'D'
                })
              }).catch(() => {});
            } catch (e) {}
            // #endregion
            return;
          }

          mediaStream = await getUserMedia({ audio: true, video: false });
          
          // #region agent log
          try {
            fetch(DEBUG_LOG_URL, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                location: 'demo.html:startRecording',
                message: 'getUserMedia success',
                data: {
                  tracks: mediaStream.getTracks().length,
                  trackKind: mediaStream.getTracks()[0]?.kind
                },
                timestamp: Date.now(),
                sessionId: 'debug-session',
                runId: 'run1',
                hypothesisId: 'E'
              })
            }).catch(() => {});
          } catch (e) {}
          // #endregion
        } catch (err) {
          const errorMsg = err.message || String(err);
          recordingStatus.textContent = `Status: microphone access denied (${errorMsg})`;
          
          // #region agent log
          try {
            fetch(DEBUG_LOG_URL, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                location: 'demo.html:startRecording',
                message: 'getUserMedia error',
                data: {
                  error: errorMsg,
                  errorName: err.name,
                  errorStack: err.stack
                },
                timestamp: Date.now(),
                sessionId: 'debug-session',
                runId: 'run1',
                hypothesisId: 'F'
              })
            }).catch(() => {});
          } catch (e) {}
          // #endregion
          return;
        }
        pendingSamples = new Float32Array(0);

        websocket = new WebSocket(`${location.protocol === "https:" ? "wss" : "ws"}://${location.host}/ws/transcribe`);

        websocket.addEventListener("open", () => {
          recordingStatus.textContent = "Status: connected";
          sessionId = crypto.randomUUID();
          
          // Get lecture_id from input or generate one
          let lectureId = lectureIdInput.value.trim();
          if (!lectureId) {
            lectureId = crypto.randomUUID();
            lectureIdInput.value = lectureId; // Show generated ID to user
          }
          
          // #region agent log
          const DEBUG_LOG_URL = 'http://127.0.0.1:7242/ingest/2b24f1d2-cbbe-41fa-9147-751f82eade36';
          try {
            fetch(DEBUG_LOG_URL, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                location: 'demo.html:websocket.open',
                message: 'Sending start action',
                data: {
                  session_id: sessionId,
                  lecture_id: lectureId,
                  presentation_id: sessionId,
                  language_code: languageSelect.value,
                  model: modelSelect.value
                },
                timestamp: Date.now(),
                sessionId: 'debug-session',
                runId: 'run1',
                hypothesisId: 'G'
              })
            }).catch(() => {});
          } catch (e) {}
          // #endregion
          
          websocket.send(JSON.stringify({
            action: "start",
            session_id: sessionId,
            presentation_id: sessionId,
            lecture_id: lectureId,
            language_code: languageSelect.value,
            model: modelSelect.value,
            enable_interim_results: true,
          }));
        });

        websocket.addEventListener("message", (event) => {
          try {
            const data = JSON.parse(event.data);
            if (data.event === "transcription") {
              appendTranscript(data.result);
            } else if (data.event === "session_started") {
              recordingStatus.textContent = "Status: recording...";
            } else if (data.event === "session_closed") {
              recordingStatus.textContent = "Status: session closed";
              startBtn.disabled = false;
              stopBtn.disabled = true;
            } else if (data.event === "error") {
              recordingStatus.textContent = `Status: error - ${data.message}`;
              startBtn.disabled = false;
              stopBtn.disabled = true;
            }
          } catch (err) {
            console.warn("Invalid message", event.data);
          }
        });

        websocket.addEventListener("close", () => {
          recordingStatus.textContent = "Status: disconnected";
          startBtn.disabled = false;
          stopBtn.disabled = true;
        });

        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        if (audioContext.state === "suspended") {
          await audioContext.resume();
        }
        const source = audioContext.createMediaStreamSource(mediaStream);

        processor = audioContext.createScriptProcessor(2048, 1, 1);
        let audioChunkCount = 0;
        processor.onaudioprocess = (event) => {
          if (!websocket || websocket.readyState !== WebSocket.OPEN) {
            return;
          }
          const inputBuffer = event.inputBuffer.getChannelData(0);
          const downsampled = downsampleBuffer(inputBuffer, audioContext.sampleRate, 16000);
          if (downsampled.length === 0) {
            return;
          }

          const combined = new Float32Array(pendingSamples.length + downsampled.length);
          combined.set(pendingSamples);
          combined.set(downsampled, pendingSamples.length);
          pendingSamples = combined;

          while (pendingSamples.length >= TARGET_CHUNK_SAMPLES) {
            const chunkSamples = pendingSamples.slice(0, TARGET_CHUNK_SAMPLES);
            pendingSamples = pendingSamples.slice(TARGET_CHUNK_SAMPLES);
            if (websocket && websocket.readyState === WebSocket.OPEN) {
              const pcm = floatTo16BitPCM(chunkSamples);
              audioChunkCount++;
              
              // #region agent log - Frontend sending audio
              const DEBUG_LOG_URL = 'http://127.0.0.1:7242/ingest/2b24f1d2-cbbe-41fa-9147-751f82eade36';
              try {
                fetch(DEBUG_LOG_URL, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    location: 'demo.html:onaudioprocess',
                    message: 'Sending audio chunk to WebSocket',
                    data: {
                      chunk_number: audioChunkCount,
                      chunk_size: pcm.byteLength,
                      websocket_state: websocket.readyState,
                      samples_count: chunkSamples.length
                    },
                    timestamp: Date.now(),
                    sessionId: 'debug-session',
                    runId: 'run1',
                    hypothesisId: 'F'
                  })
                }).catch(() => {});
              } catch (e) {}
              // #endregion
              
              // Log every 10 chunks to avoid spam
              if (audioChunkCount % 10 === 0) {
                console.log(`Sent ${audioChunkCount} audio chunks to server`);
              }
              
              websocket.send(pcm);
            }
          }
        };

        source.connect(processor);
        processor.connect(audioContext.destination);

        startBtn.disabled = true;
        stopBtn.disabled = false;
        recordingStatus.textContent = "Status: connecting...";
      }

      async function stopRecording() {
        stopBtn.disabled = true;

        if (processor) {
          processor.disconnect();
          processor = null;
        }
        if (audioContext) {
          await audioContext.close();
          audioContext = null;
        }
        if (mediaStream) {
          mediaStream.getTracks().forEach((track) => track.stop());
          mediaStream = null;
        }
        pendingSamples = new Float32Array(0);

        if (websocket && websocket.readyState === WebSocket.OPEN) {
          websocket.send(JSON.stringify({ action: "stop" }));
        }
        setTimeout(() => {
          if (websocket) {
            websocket.close();
            websocket = null;
          }
        }, 250);

        recordingStatus.textContent = "Status: idle";
        startBtn.disabled = false;
        stopBtn.disabled = true;
        sessionId = null;
      }

      startBtn.addEventListener("click", () => {
        startRecording();
      });

      stopBtn.addEventListener("click", () => {
        stopRecording();
      });

      window.addEventListener("beforeunload", () => {
        if (websocket && websocket.readyState === WebSocket.OPEN) {
          websocket.close();
        }
      });
    </script>
  </body>
</html>

